# Legal Research Engine for Courts with LangGraph

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.49.1-red.svg)](https://streamlit.io)
[![LangGraph](https://img.shields.io/badge/LangGraph-Multi--Agent-blue.svg)](https://github.com/langchain-ai/langgraph)

A comprehensive AI-powered legal research assistant built with LangChain, **LangGraph multi-agent workflows**, Streamlit, and local LM Studio models. This system provides intelligent document analysis, case law research, precedent analysis, and citation management for Indian legal documents.

## ğŸ†• **New: LangGraph Multi-Agent Workflows**

This version introduces advanced **LangGraph workflows** with specialized AI agents for comprehensive legal analysis:

- ğŸ¯ **Orchestrator Agent**: Plans and coordinates research workflow
- ğŸ“š **Document Retrieval Agent**: Performs advanced RAG-based search  
- ğŸ“„ **Case Brief Agent**: Generates structured legal summaries
- âš–ï¸ **Precedent Analysis Agent**: Identifies similar cases and principles
- ğŸ“ **Citation Extraction Agent**: Automatically extracts legal citations
- ğŸ”„ **Report Synthesizer**: Combines all analysis into comprehensive reports

**[ğŸ“– Read the Complete LangGraph Integration Guide](LANGGRAPH_GUIDE.md)**

## Quick Start

```bash
# Clone the repository
git clone https://github.com/PiKa919/Research-Engine-For-Courts.git
cd Research-Engine-For-Courts

# Install dependencies (now includes LangGraph)
pip install -r requirements.txt

# Run the application with LangGraph workflows
streamlit run app.py
```

## Features

### ğŸ” Intelligent Document Processing
- **Enhanced PDF Processing**: Advanced text extraction from legal documents
- **Metadata Extraction**: Automatic extraction of sections, court mentions, and legal terms
- **Quality Assessment**: Document quality scoring and validation
- **Adaptive Text Splitting**: Smart chunking optimized for legal content

### ğŸ¤– AI-Powered Analysis
- **ğŸ†• LangGraph Multi-Agent Workflows**: Sophisticated orchestration of specialized AI agents
- **Local LLM Integration**: Uses LM Studio for complete privacy and cost control
- **Retrieval-Augmented Generation (RAG)**: Context-aware legal research
- **Multi-Model Support**: Separate models for embeddings and chat
- **Legal-Specific Prompts**: Tailored prompts for Indian legal system
- **ğŸ†• Human-in-the-Loop**: Built-in approval workflows for critical decisions

### ğŸ“Š Advanced Tools
- **Citation Graph Visualization**: Interactive network of legal citations
- **ğŸ†• Automated Case Brief Generation**: AI-generated structured legal summaries
- **ğŸ†• Advanced Precedent Analysis**: Multi-agent case law research
- **Document Comparison**: Side-by-side analysis of multiple documents
- **Timeline Builder**: Chronological case progression tracking
- **ğŸ†• Workflow Monitoring**: Real-time tracking of analysis progress

### ğŸ¯ Legal Research Capabilities
- **Indian Law Focus**: Specialized for Indian legal system and courts
- **ğŸ†• Automatic Citation Extraction**: AI-powered legal reference identification
- **Case Law Research**: Intelligent precedent finding and analysis
- **Document Similarity**: Semantic search across legal documents
- **ğŸ†• Confidence Scoring**: Quality assessment of analysis results

## Installation

### Prerequisites
- **Python 3.8+**: Programming language runtime
- **LM Studio**: Local AI model server ([download](https://lmstudio.ai/))
- **Git**: Version control system

### System Requirements
- **RAM**: Minimum 8GB, Recommended 16GB+
- **Storage**: 5GB+ free space for models and documents
- **OS**: Windows 10/11, macOS, or Linux

### Setup Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/PiKa919/Research-Engine-For-Courts.git
   cd Research-Engine-For-Courts
   ```

2. **Create conda environment**
   ```bash
   conda create -n legal python=3.11 -y
   conda activate legal
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install LM Studio**
   - Download from [lmstudio.ai](https://lmstudio.ai/)
   - Install and launch LM Studio
   - Download models:
     - Embedding: `text-embedding-embeddinggemma-300m-qat`
     - Chat: Any compatible model (Llama 2, Mistral, etc.)

5. **Configure LM Studio**
   - Go to "Developer" tab
   - Load your downloaded models
   - Start local server (should run on `http://127.0.0.1:1234`)

## Usage

### Prepare Documents
```bash
# Add PDF documents to the data/ folder
# Then run ingestion
python src/ingest.py
```

### Run the Application
```bash
# Start the Streamlit app
streamlit run app.py --server.headless true --server.port 8501

# Access at: http://localhost:8501
```

### Main Features

#### ğŸ’¬ **Chat** - Interactive Legal Research
Ask questions about your legal documents and get AI-powered answers with citations.

#### ğŸ“Š **Citation Graph** - Visual Citation Network
Interactive visualization of legal citations and case relationships.

#### ï¿½ **Citation Analysis** - Document Analytics
Frequency analysis and citation patterns in your document collection.

#### ğŸ“‹ **Case Brief Generator** - Automated Briefs
Generate structured case briefs with key legal elements.

#### âš–ï¸ **Precedent Analysis** - Case Similarity
Find similar legal cases and analyze legal principles.

#### ğŸ“„ **Document Comparison** - Side-by-Side Analysis
Compare multiple legal documents with legal implications.

#### ğŸ“Š **Evaluation** - System Performance
DeepEval metrics and system accuracy assessment.
- **Embedding Model**: `text-embedding-embeddinggemma-300m-qat` or similar
- **Chat Model**: Any compatible model (Llama 2, Mistral, etc.)

## ğŸ“¦ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/PiKa919/Research-Engine-For-Courts.git
cd "Research Engine For Courts"
```

### 2. Create Conda Environment
```bash
# Create new environment
conda create -n legal python=3.11 -y

# Activate environment
conda activate legal
## Recent Updates

### v1.0.1 - September 2025
- **âœ… Fixed** `langchain_experimental` import error - added missing package dependency
- **âœ… Fixed** RAG chain TypeError - corrected chain structure for proper string input handling
- **âœ… Improved** error handling and logging throughout the application
- **âœ… Enhanced** documentation and setup instructions

## Project Structure

```
Research-Engine-For-Courts/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                      # FastAPI REST endpoints
â”‚   â”œâ”€â”€ config.py                   # Configuration management
â”‚   â”œâ”€â”€ retrieval.py                # RAG implementation & vector search
â”‚   â”œâ”€â”€ ingest.py                   # Document ingestion pipeline
â”‚   â”œâ”€â”€ enhanced_document_processor.py  # Advanced document processing
â”‚   â”œâ”€â”€ precedent_analyzer.py       # Legal precedent analysis
â”‚   â”œâ”€â”€ document_comparator.py      # Document comparison tools
â”‚   â”œâ”€â”€ case_brief_generator.py     # Automated case brief generation
â”‚   â”œâ”€â”€ knowledge_graph.py          # Citation graph visualization
â”‚   â”œâ”€â”€ evaluation.py               # System evaluation & metrics
â”‚   â”œâ”€â”€ caching.py                  # Performance caching system
â”‚   â”œâ”€â”€ monitoring.py               # Performance monitoring
â”‚   â””â”€â”€ evaluation.py               # Model evaluation tools
â”œâ”€â”€ data/                           # Legal document storage
â”œâ”€â”€ chroma/                         # Vector database storage
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ pyrightconfig.json              # Python type checking
â””â”€â”€ README.md                       # This file
```

## Configuration

### Model Configuration
```python
# LM Studio models (local)
EMBEDDING_MODEL = "text-embedding-embeddinggemma-300m-qat"
LLM_MODEL = "local-model"

# Performance settings
MAX_TOKENS = 2048
TEMPERATURE = 0.1
TOP_P = 0.9
```

### Environment Variables
```bash
# Optional: Create .env file for additional configuration
LM_STUDIO_BASE_URL=http://127.0.0.1:1234
DATA_PATH=./data
CHROMA_PATH=./chroma
```

## API Reference

### REST API Endpoints

The system provides REST API endpoints for integration:

- `GET /health` - Health check
- `POST /query/` - Synchronous legal research query
- `POST /query/async` - Asynchronous legal research query
- `GET /documents/` - List available documents
- `POST /documents/ingest` - Ingest new documents

### Python API

```python
from src.retrieval import create_rag_chain

# Initialize the system
async_rag_chain, sync_rag_chain = create_rag_chain()

# Perform legal research
result = sync_rag_chain("What are the provisions for commercial courts?")
print(result["answer"])
```

## Troubleshooting

### Common Issues

#### LM Studio Connection
```bash
# Check if LM Studio server is running
curl http://127.0.0.1:1234/v1/models
```

#### Import Errors
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

#### Vector Store Issues
```bash
# Reset vector database
rm -rf chroma/
python src/ingest.py
```

#### Memory Issues
- Increase RAM allocation in LM Studio
- Use smaller models
- Process documents in smaller batches

## Performance

### Benchmarks
- **Document Processing**: ~50 pages/minute
- **Query Response**: < 3 seconds average
- **Vector Search**: < 100ms for similarity search
- **Memory Usage**: ~2GB base + 0.5GB per 1000 documents

### Optimization Tips
- Use GPU acceleration in LM Studio for better performance
- Batch document ingestion for large collections
- Configure appropriate chunk sizes for your documents
- Monitor system resources during heavy usage

## Contributing

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes
4. Test thoroughly
5. Submit a pull request

### Code Standards
- Follow PEP 8 for Python code
- Add docstrings to all functions
- Include type hints where possible
- Write comprehensive tests

### Adding New Features
1. Create feature in appropriate module in `src/`
2. Update configuration if needed
3. Add to Streamlit interface in `app.py`
4. Update documentation

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **LangChain** - Framework for LLM applications
- **Streamlit** - Web application framework
- **LM Studio** - Local AI model server
- **Chroma** - Vector database
- **PyVis** - Network visualization

---

**Built with â¤ï¸ for legal professionals and researchers**

*Last updated: September 22, 2025*
```bash
# Make sure you're in the project directory
cd "c:\FILES_PIKA\Research Engine For Courts"

# Activate environment
conda activate legal

# Run the application
streamlit run app.py --server.headless true --server.port 8501
```

### Access the Application
- **Open your browser**
- **Navigate to**: `http://localhost:8501`
- **The application will load with multiple tabs**

## ğŸ“– Usage

### Main Interface Tabs

#### 1. ğŸ’¬ **Chat** - Interactive Legal Research
- Ask questions about your legal documents
- Get AI-powered answers with citations
- Explore document relationships

#### 2. ğŸ“Š **Citation Graph** - Visual Citation Network
- Interactive visualization of legal citations
- Explore connections between cases
- Network analysis of legal precedents

#### 3. ğŸ“ˆ **Citation Analysis** - Document Analytics
- Frequency analysis of citations
- Document usage statistics
- Citation patterns and trends

#### 4. ğŸ“‹ **Case Brief Generator** - Automated Briefs
- Generate structured case briefs
- Extract key legal elements
- Professional legal document formatting

#### 5. âš–ï¸ **Precedent Analysis** - Case Similarity
- Find similar legal cases
- Analyze legal principles and holdings
- Precedent research and validation

#### 6. ğŸ“„ **Document Comparison** - Side-by-Side Analysis
- Compare multiple legal documents
- Identify similarities and differences
- Legal implications analysis

#### 7. ğŸ“Š **Evaluation** - System Performance
- DeepEval metrics and benchmarks
- System accuracy assessment
- Performance optimization insights

### Example Usage

#### Basic Q&A
```
Question: "What are the key principles of Section 138 of the Negotiable Instruments Act?"

Response: The system will search your documents and provide:
- Relevant case law
- Section references
- Legal analysis with citations
```

#### Document Upload
```python
# Add new documents
# 1. Place PDF in data/ folder
# 2. Run: python src/ingest.py
# 3. New documents are automatically indexed
```

## ğŸ“ Project Structure

```
Research Engine For Courts/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                     # Alternative app interface
â”‚   â”œâ”€â”€ config.py                  # Configuration settings
â”‚   â”œâ”€â”€ retrieval.py               # RAG implementation
â”‚   â”œâ”€â”€ ingest.py                  # Data ingestion pipeline
â”‚   â”œâ”€â”€ enhanced_document_processor.py  # Document processing
â”‚   â”œâ”€â”€ precedent_analyzer.py      # Legal precedent analysis
â”‚   â”œâ”€â”€ document_comparator.py     # Document comparison
â”‚   â”œâ”€â”€ case_brief_generator.py    # Case brief generation
â”‚   â”œâ”€â”€ knowledge_graph.py         # Citation graph visualization
â”‚   â””â”€â”€ evaluation.py              # System evaluation
â”œâ”€â”€ data/                          # Legal document storage
â”‚   â”œâ”€â”€ Commercial Courts Act, 2015.pdf
â”‚   â”œâ”€â”€ Commercial Courts Rules, 2019.pdf
â”‚   â””â”€â”€ ...
â”œâ”€â”€ chroma/                        # Vector database storage
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ pyrightconfig.json             # Python type checking
```

## âš™ï¸ Configuration

### Model Configuration (`src/config.py`)
```python
# LM Studio models (local)
EMBEDDING_MODEL = "text-embedding-embeddinggemma-300m-qat"
LLM_MODEL = "local-model"  # LM Studio will use loaded model

# Paths
DATA_PATH = "data/"
CHROMA_PATH = "chroma/"
```

### Environment Variables
Create a `.env` file for sensitive configurations:
```bash
# .env file
GOOGLE_API_KEY=your_key_here  # Only if using Google models (not recommended)
```

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. **Import Errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

#### 2. **LM Studio Connection Issues**
- **Check if LM Studio is running**
- **Verify server URL**: `http://127.0.0.1:1234`
- **Ensure models are loaded in LM Studio**
- **Check firewall settings**

#### 3. **Vector Store Errors**
```bash
# Reset vector store
rm -rf chroma/
python src/ingest.py
```

#### 4. **Memory Issues**
- **Increase RAM allocation in LM Studio**
- **Use smaller models**
- **Process documents in smaller batches**

#### 5. **Port Conflicts**
```bash
# Use different port
streamlit run app.py --server.port 8502
```

### Performance Optimization

#### For Better Speed:
1. **Use GPU in LM Studio** (if available)
2. **Optimize model parameters**
3. **Use smaller embedding models**
4. **Increase batch sizes in ingestion**

#### For Better Accuracy:
1. **Use larger models**
2. **Fine-tune prompts**
3. **Add more legal documents**
4. **Improve document preprocessing**

## ğŸ¤ Contributing

### Development Setup
1. **Fork the repository**
2. **Create a feature branch**:
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Make your changes**
4. **Test thoroughly**
5. **Submit a pull request**

### Code Standards
- **Follow PEP 8** for Python code
- **Add docstrings** to all functions
- **Include type hints** where possible
- **Write comprehensive tests**

### Adding New Features
1. **Create feature in appropriate module**
2. **Update configuration if needed**
3. **Add to Streamlit interface**
4. **Update documentation**

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangChain** - Framework for LLM applications
- **Streamlit** - Web application framework
- **LM Studio** - Local AI model server
- **Chroma** - Vector database
- **PyVis** - Network visualization

## ğŸ“ Support

For support and questions:
- **Open an issue** on GitHub
- **Check the troubleshooting section**
- **Review LM Studio documentation**

---

**Built with â¤ï¸ for legal professionals and researchers**

*Last updated: September 16, 2025*
